{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.training.example import Example\n",
    "\n",
    "dataset_path = os.path.abspath('../../data/datasets/ner-swiss-receipts.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.abspath(\"../../data/datasets/ner-swiss-receipts.json\")  # Path to your training data file\n",
    "OUTPUT_DIR = os.path.abspath(\"../models/receipts-ner-v02\")  # TODO: make sure to use a new version\n",
    "ITERATIONS = 30  # Number of training iterations\n",
    "BATCH_SIZE = 8  # Batch size for training\n",
    "DROPOUT = 0.5  # Dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat for Spacy & Remove unwanted Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for entry in dataset:\n",
    "    text = entry[\"text\"]\n",
    "    entities = [entity for entity in entry[\"entities\"] if entity[2] == 'RECEIPT_ITEM']\n",
    "    data.append((text, {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Data:\n",
      "-----------------------------------------\n",
      "MANOR”\n",
      "\n",
      "www.manor.ch\n",
      "Emmen Center\n",
      "6032 Emmen\n",
      "041 269 46 99\n",
      "\n",
      "[] [e]\n",
      "EE\n",
      "\n",
      "' Es bediente Sie:\n",
      "\n",
      "S, Elshaz1ly 09.07.2021 11:91\n",
      "B Strohhut 20.95 A\n",
      "2003001006833\n",
      "N Total Artikel: 1 20.95\n",
      "N American Express 20.95\n",
      ". Total Zahlungsmittel 20.\n",
      "\n",
      "AMEX KXKKKKOKKROOOOGHKXH42 118354 31503551\n",
      "Herzlicher: Dank für Ihren Einkauf\n",
      "\n",
      "CHE-116.267.650 MuSt\n",
      "\n",
      "Code betrag Satz MUST\n",
      "A 20.95 7.70 1.50\n",
      "Manoı AG, Base) Total 1.50\n",
      "\n",
      "» 206 251 #20508 122579 «\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "Entity-Type: RECEIPT_ITEM, Entity text: B Strohhut 20.95 A\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Training Data:\")\n",
    "sample_text, sample_annotaiton = train[0]\n",
    "print(\"-----------------------------------------\")\n",
    "print(sample_text)\n",
    "print(\"-----------------------------------------\")\n",
    "for ent in sample_annotaiton.get(\"entities\"):\n",
    "    print(f'Entity-Type: {ent[2]}, Entity text: {sample_text[ent[0]:ent[1]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an emtpy spacy model for specific language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a blank model, or replace with spacy.load(\"en_core_web_sm\")\n",
    "nlp = spacy.blank(\"de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Named-Entity Recognition Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Labels to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timon/.pyenv/versions/3.10.16/envs/dspro/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"mi rolino idee MIGROL\n",
      "\n",
      "Migrol Service\n",
      "Überriauerst...\" with entities \"[[255, 282, 'RECEIPT_ITEM'], [283, 306, 'RECEIPT_I...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/timon/.pyenv/versions/3.10.16/envs/dspro/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"AUS\n",
      "FREUDE\n",
      "AM\n",
      "GESCHMACK\n",
      "\n",
      "Macchi AG Bäckerei\n",
      "Überna...\" with entities \"[[213, 234, 'RECEIPT_ITEM'], [235, 267, 'RECEIPT_I...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/30, Loss: 5948.5698\n",
      "Epoch 2/30, Loss: 1468.1434\n",
      "Epoch 3/30, Loss: 1504.7682\n",
      "Epoch 4/30, Loss: 850.7117\n",
      "Epoch 5/30, Loss: 856.3832\n",
      "Epoch 6/30, Loss: 839.6247\n",
      "Epoch 7/30, Loss: 781.5732\n",
      "Epoch 8/30, Loss: 633.9720\n",
      "Epoch 9/30, Loss: 519.0314\n",
      "Epoch 10/30, Loss: 429.3792\n",
      "Epoch 11/30, Loss: 350.1024\n",
      "Epoch 12/30, Loss: 309.6041\n",
      "Epoch 13/30, Loss: 269.8421\n",
      "Epoch 14/30, Loss: 241.0048\n",
      "Epoch 15/30, Loss: 236.3765\n",
      "Epoch 16/30, Loss: 224.4710\n",
      "Epoch 17/30, Loss: 155.5443\n",
      "Epoch 18/30, Loss: 164.9194\n",
      "Epoch 19/30, Loss: 176.4708\n",
      "Epoch 20/30, Loss: 147.3633\n",
      "Epoch 21/30, Loss: 129.1356\n",
      "Epoch 22/30, Loss: 134.7334\n",
      "Epoch 23/30, Loss: 118.7207\n",
      "Epoch 24/30, Loss: 119.9999\n",
      "Epoch 25/30, Loss: 111.2022\n",
      "Epoch 26/30, Loss: 112.1037\n",
      "Epoch 27/30, Loss: 104.7212\n",
      "Epoch 28/30, Loss: 85.9288\n",
      "Epoch 29/30, Loss: 94.0414\n",
      "Epoch 30/30, Loss: 74.5331\n"
     ]
    }
   ],
   "source": [
    "# Disable other pipes during training for efficiency\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "        \n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(ITERATIONS):\n",
    "        random.shuffle(examples)\n",
    "        losses = {}\n",
    "        for batch in spacy.util.minibatch(examples, size=BATCH_SIZE):\n",
    "            nlp.update(batch, drop=DROPOUT, losses=losses)\n",
    "        print(f\"Epoch {epoch + 1}/{ITERATIONS}, Loss: {losses['ner']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /Users/timon/git/dspro1-receipt-ocr/named-entity-recognition/models/receipts-ner-v02...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "nlp.to_disk(OUTPUT_DIR)\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
